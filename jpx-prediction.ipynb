{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport pandas as pd \nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom decimal import ROUND_HALF_UP, Decimal\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport warnings\nimport re\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 25)\npd.set_option('display.max_colwidth', 3000)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T20:06:30.560973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Things to add in my model\n\n## to add attributes \nfrom sklearn.preprocessing import OneHotEncoder\n\n## Create pipeline\n- Select relevant 2000\n- Combine frames\n- Hot encoding\n- Adjust prices (split/SplitReverse)\n- Create features\n- Standard Scaler\n- Drop labels\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import FunctionTransformer\n\n\n## create a function to replace 0 by NaN\ndef replace_0_2_NaN(data):\n    data[data == 0] = np.nan\n    return data\n\n\nnum0_pipeline = Pipeline([\n        ('zeros2NaN',FunctionTransformer(func = replace_0_2_NaN,validate=False)),\n        ('imputer', SimpleImputer(strategy=\"median\")),\n        ('log',FunctionTransformer(np.log1p, validate=True)),\n        ('std_scaler', StandardScaler()),\n    ])\n\nhousing_num_tr = num0_pipeline.fit_transform(housing[['BuildingArea','Landsize']])\n\n\n\nhousing_num_tr = num_pipeline.fit_transform(housing_num)\n\n\n\ncat_pipeline = Pipeline([\n        ('imputer', SimpleImputer(strategy=\"constant\",fill_value='Unknown')),\n        ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore')),\n    ])\n\n\n\nfrom sklearn.compose import ColumnTransformer\n\nnum_attribs0 = ['Landsize','BuildingArea']\nnum_attribs1 = list(housing_num)\ncat_attribs = [\"CouncilArea\",'Type','Suburb','Postcode']\n\n\nfull_pipeline = ColumnTransformer([\n        (\"num0\", num0_pipeline, num_attribs0),\n        (\"num1\", num_pipeline, num_attribs1),\n        (\"cat\", cat_pipeline, cat_attribs),\n    ])\n\nhousing_prepared = full_pipeline.fit_transform(housing)\n\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"**Data Pipeline**","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline \nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.compose import ColumnTransformer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**MLs Model**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error\nfrom lightgbm import LGBMRegressor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Local","metadata":{}},{"cell_type":"markdown","source":"%%time\nfinancials_df = pd.read_csv(\"train_files/financials.csv\")\noptions_df = pd.read_csv(\"train_files/options.csv\")\nsecondary_stock_prices_df = pd.read_csv(\"train_files/secondary_stock_prices.csv\")\nstock_prices_df = pd.read_csv(\"train_files/stock_prices.csv\")\ntrades_df = pd.read_csv(\"train_files/trades.csv\")\nstocks_df = pd.read_csv(\"stock_list.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-04T13:18:21.33672Z","iopub.execute_input":"2022-06-04T13:18:21.336988Z","iopub.status.idle":"2022-06-04T13:18:21.366956Z","shell.execute_reply.started":"2022-06-04T13:18:21.33696Z","shell.execute_reply":"2022-06-04T13:18:21.366157Z"}}},{"cell_type":"markdown","source":"### Kaggle","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Datasets**","metadata":{}},{"cell_type":"code","source":"%%time \nfinancials_df = pd.read_csv(\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/financials.csv\")\noptions_df = pd.read_csv(\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/options.csv\")\nsecondary_stock_prices_df = pd.read_csv(\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/secondary_stock_prices.csv\")\nstock_prices_df = pd.read_csv(\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv\")\ntrades_df = pd.read_csv(\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/trades.csv\")\nstocks_df = pd.read_csv(\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/stock_list.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Suplemental files**","metadata":{}},{"cell_type":"code","source":"financials_info = pd.read_csv(\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/data_specifications/stock_fin_spec.csv\")\noptions_info = pd.read_csv(\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/data_specifications/options_spec.csv\")\nstock_prices_info = pd.read_csv(\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/data_specifications/stock_price_spec.csv\")\ntrades_info = pd.read_csv(\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/data_specifications/trades_spec.csv\")\nstocks_info = pd.read_csv(\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/data_specifications/stock_list_spec.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 0. Utils","metadata":{}},{"cell_type":"markdown","source":"**Merging stock prices with stock metadata**","metadata":{}},{"cell_type":"code","source":"def merge_metadata(stock_prices_df, df_stocks):\n    col = [\"SecuritiesCode\",\"Name\",\"Section/Products\",\"NewMarketSegment\",\"33SectorCode\",\"33SectorName\",\"17SectorCode\",\"17SectorName\",\"NewIndexSeriesSizeCode\",\"NewIndexSeriesSize\",\"IssuedShares\",\"MarketCapitalization\"]\n    df_prices = pd.merge(stock_prices_df, df_stocks[col], on='SecuritiesCode')\n    display(df_prices.head())\n    return df_prices","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**OHLCV Chart plot**","metadata":{}},{"cell_type":"code","source":"def plot_candle_with_target(df_prices, stock_code, prime=True):\n    \"\"\"Plot OHLCV plot with target series.\n    \n    Parameters:\n        stock_code: int, code of the stock\n        prime: bool, whether the stock to plot is prime or not\n    \"\"\"\n    df_ = df_prices.copy() if prime else df_prices_sec.copy()\n    df_ = df_[df_['SecuritiesCode'] == stock_code]\n    dates = df_['Date'].values\n    ohlc = {\n        'open': df_['Open'].values, \n        'high': df_['High'].values, \n        'low': df_['Low'].values, \n        'close': df_['Close'].values\n    }\n    vol = df_['Volume'].values\n    target = df_['Target'].values\n    \n    fig = make_subplots(rows=3, cols=1, shared_xaxes=True, x_title='Date')\n    fig.add_trace(go.Candlestick(x=dates, name='OHLC', **ohlc),\n                  row=1, col=1)\n    fig.add_trace(go.Bar(x=dates, y=vol, name='Volume'),\n                  row=2, col=1)\n    fig.add_trace(go.Scatter(x=dates, y=target, name='Target'),\n                  row=3, col=1)\n    fig.update_layout(\n        title=f\"OHLCV Chart with Target Series (Stock {stock_code})\",\n    )\n    fig.update(layout_xaxis_rangeslider_visible=False)\n    fig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_candle_with_target_adjusted(df_prices, stock_code, prime=True):\n    \"\"\"Plot OHLCV plot with target series.\n    \n    Parameters:\n        stock_code: int, code of the stock\n        prime: bool, whether the stock to plot is prime or not\n    \"\"\"\n    df_ = df_prices.copy() if prime else df_prices_sec.copy()\n    df_ = df_[df_['SecuritiesCode'] == stock_code]\n    dates = df_['Date'].values\n    ohlc = {\n        'open': df_['AdjustedOpen'].values, \n        'high': df_['AdjustedHigh'].values, \n        'low': df_['AdjustedLow'].values, \n        'close': df_['AdjustedClose'].values\n    }\n    vol = df_['Volume'].values\n    target = df_['Target'].values\n    \n    fig = make_subplots(rows=3, cols=1, shared_xaxes=True, x_title='Date')\n    fig.add_trace(go.Candlestick(x=dates, name='OHLC', **ohlc),\n                  row=1, col=1)\n    fig.add_trace(go.Bar(x=dates, y=vol, name='Volume'),\n                  row=2, col=1)\n    fig.add_trace(go.Scatter(x=dates, y=target, name='Target'),\n                  row=3, col=1)\n    fig.update_layout(\n        title=f\"OHLCV Chart with Target Series (Stock {stock_code})\",\n    )\n    fig.update(layout_xaxis_rangeslider_visible=False)\n    fig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation function","metadata":{}},{"cell_type":"code","source":"def calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size: int = 200, toprank_weight_ratio: float = 2) -> float:\n    \"\"\"\n    Args:\n        df (pd.DataFrame): predicted results\n        portfolio_size (int): # of equities to buy/sell\n        toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n    Returns:\n        (float): sharpe ratio\n    \"\"\"\n    def _calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n        \"\"\"\n        Args:\n            df (pd.DataFrame): predicted results\n            portfolio_size (int): # of equities to buy/sell\n            toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n        Returns:\n            (float): spread return\n        \"\"\"\n        assert df['Rank'].min() == 0\n        assert df['Rank'].max() == len(df['Rank']) - 1\n        weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n        purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        return purchase - short\n\n    buf = df.groupby('Date').apply(_calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n    sharpe_ratio = buf.mean() / buf.std()\n    return sharpe_ratio","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Adjust Split-Reverse/split price**","metadata":{}},{"cell_type":"code","source":"def adjust_price(price):\n    \"\"\"\n    Args:\n        price (pd.DataFrame)  : pd.DataFrame include stock_price\n    Returns:\n        price DataFrame (pd.DataFrame): stock_price with generated AdjustedClose\n    \"\"\"\n    # transform Date column into datetime\n    price.loc[: ,\"Date\"] = pd.to_datetime(price.loc[: ,\"Date\"], format=\"%Y-%m-%d\")\n\n    def generate_adjusted_close(df):\n        \"\"\"\n        Args:\n            df (pd.DataFrame)  : stock_price for a single SecuritiesCode\n        Returns:\n            df (pd.DataFrame): stock_price with AdjustedClose for a single SecuritiesCode\n        \"\"\"\n        # sort data to generate CumulativeAdjustmentFactor\n        df = df.sort_values(\"Date\", ascending=False)\n        # generate CumulativeAdjustmentFactor\n        df.loc[:, \"CumulativeAdjustmentFactor\"] = df[\"AdjustmentFactor\"].cumprod()\n        \n        \n        # generate AdjustedClose\n        df.loc[:, \"AdjustedClose\"] = (\n            df[\"CumulativeAdjustmentFactor\"] * df[\"Close\"]\n        ).map(lambda x: float(\n            Decimal(str(x)).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP)\n        )) \n\n        # generate AdjustedOpen\n        df.loc[:, \"AdjustedOpen\"] = (\n            df[\"CumulativeAdjustmentFactor\"] * df[\"Open\"]\n        ).map(lambda x: float(\n            Decimal(str(x)).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP)\n        ))\n        \n        # generate AdjustedHigh\n        df.loc[:, \"AdjustedHigh\"] = (\n            df[\"CumulativeAdjustmentFactor\"] * df[\"High\"]\n        ).map(lambda x: float(\n            Decimal(str(x)).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP)\n        ))\n        \n        # generate Low\n        df.loc[:, \"AdjustedLow\"] = (\n            df[\"CumulativeAdjustmentFactor\"] * df[\"Low\"]\n        ).map(lambda x: float(\n            Decimal(str(x)).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP)\n        ))\n        \n        \n        # reverse order\n        df = df.sort_values(\"Date\")\n        # to fill AdjustedClose, replace 0 into np.nan\n        df.loc[df[\"AdjustedClose\"] == 0, \"AdjustedClose\"] = np.nan\n        # forward fill AdjustedClose\n       \n        #df.loc[:, \"AdjustedClose\"] = df.loc[:, \"AdjustedClose\"].ffill()\n        \n        df.loc[:, \"AdjustedClose\"] = df.loc[:, \"AdjustedClose\"].interpolate(method='linear',limit_direction='backward')\n        df.loc[:, \"AdjustedOpen\"] = df.loc[:, \"AdjustedOpen\"].interpolate(method='linear',limit_direction='backward')\n        df.loc[:, \"AdjustedHigh\"] = df.loc[:, \"AdjustedHigh\"].interpolate(method='linear',limit_direction='backward')\n        df.loc[:, \"AdjustedLow\"] = df.loc[:, \"AdjustedLow\"].interpolate(method='linear',limit_direction='backward')\n\n        return df\n\n    # generate AdjustedClose\n    price = price.sort_values([\"SecuritiesCode\", \"Date\"])\n    price = price.groupby(\"SecuritiesCode\").apply(generate_adjusted_close).reset_index(drop=True)\n    price.drop(columns=['Open', 'High','Low','Close','AdjustmentFactor'],inplace =True)\n    #price.set_index(\"Date\", inplace=True)\n    return price","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Feature extraction**","metadata":{}},{"cell_type":"code","source":"def generate_feature(price):\n    \"\"\"\n    Args:\n        price (pd.DataFrame)  : pd.DataFrame include stock_price\n    Returns:\n        price DataFrame (pd.DataFrame): stock_price with generated AdjustedClose\n    \"\"\"\n    # transform Date column into datetime\n\n    def generate_feature_close(df):\n        \"\"\"\n        Args:\n            df (pd.DataFrame)  : stock_price for a single SecuritiesCode\n        Returns:\n            df (pd.DataFrame): Features for a single SecuritiesCode\n        \"\"\"\n        # sort data to generate CumulativeAdjustmentFactor\n        df = df.sort_values(\"Date\", ascending=False)\n        \n        # generate PriceChanges\n        period = [5,10,21,33]\n        for i in period:\n            df[f\"pct{i}\"] = df[\"AdjustedClose\"].pct_change(i)\n            df.loc[:, f\"pct{i}\"] = df.loc[:, f\"pct{i}\"].interpolate(method='linear',limit_direction='backward')\n            df.loc[:,f\"Volatility_{i}\"] = np.log(df[\"AdjustedClose\"]).diff().rolling(i).std()\n            df.loc[:, f\"Volatility_{i}\"] = df.loc[:, f\"Volatility_{i}\"].interpolate(method='linear',limit_direction='backward')\n\n        period_avg = [10,20,50,60]\n        for i in period_avg:\n         \n            # generate SMA\n            df[f\"SMA_{i}\"] = df['AdjustedClose'].rolling(window=i).mean()\n            df.loc[:, f\"SMA_{i}\"] = df.loc[:, f\"SMA_{i}\"].interpolate(method='linear',limit_direction='backward')\n          \n            # generate EMA\n            df[f\"EMA_{i}\"] = df['AdjustedClose'].ewm(span=i,adjust=False).mean()\n            df.loc[:, f\"EMA_{i}\"] = df.loc[:, f\"EMA_{i}\"].interpolate(method='linear',limit_direction='backward')\n        \n        # reverse order\n        df = df.sort_values(\"Date\")\n\n        return df\n\n    # generate AdjustedClose\n    price = price.sort_values([\"SecuritiesCode\", \"Date\"])\n    price = price.groupby(\"SecuritiesCode\").apply(generate_feature_close).reset_index(drop=True)\n    #price.set_index(\"Date\", inplace=True)\n    return price","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"### Stock prices\nstock_prices.csv","metadata":{}},{"cell_type":"markdown","source":"File Description\nThe core file of interest, including the daily closing price for each stock and the target column. Following is column information recorded in stock_price_spec.csv:\n\n    RowId: Unique ID of price records, the combination of Date and SecuritiesCode.\n    Date: Trade date.\n    SecuritiesCode: Local securities code.\n    Open: First traded price on a day.\n    High: Highest traded price on a day.\n    Low: Lowest traded price on a day.\n    Close: Last traded price on a day.\n    Volume: Number of traded stocks on a day.\n    AdjustmentFactor: Used to calculate theoretical price/volume when split/reverse-split happens (NOT including dividend/allotment of shares).\n    ExpectedDividend: Expected dividend value for ex-right date. This value is recorded 2 business days before ex-dividend date.\n    SupervisionFlag: Flag of securities under supervision and securities to be delisted, for more information, please see here.\n    Target: Change ratio of adjusted closing price between t+2 and t+1 where t+0 is trade date.","metadata":{}},{"cell_type":"code","source":"stock_prices_info","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(stock_prices_df.head(5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stock_prices_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stock_prices_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Missing values**","metadata":{}},{"cell_type":"code","source":"display(pd.isna(stock_prices_df).sum()/len(stock_prices_df)*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_high = stock_prices_df[stock_prices_df[\"High\"].isna()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(missing_high.head(5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(missing_high.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_high[\"Date\"].nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_high[\"Date\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_missing_high_df = missing_high[\"Date\"].value_counts().to_frame().reset_index()\nplot_missing_high_df.rename(columns = {'index':'Date', 'Date':'Count'}, inplace = True)\nplot_missing_high_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2020-10-01 is the day with the most amount of missing data","metadata":{}},{"cell_type":"code","source":"plot_missing_high_df[\"Date\"] = pd.to_datetime(plot_missing_high_df[\"Date\"])\nplot_missing_high_df.sort_values(by=\"Date\",inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=plot_missing_high_df[\"Date\"], \n                         y=plot_missing_high_df[\"Count\"], \n                         mode='lines'))\n\nfig.update_layout(\n    title=f\"Stocks without Prices Count per Date\",\n    xaxis_title=\"Date\",\n    yaxis_title=\"Count\",\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_Target = stock_prices_df[stock_prices_df[\"Target\"].isna()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(missing_Target.head(5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(missing_Target.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_Target[\"Date\"].nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_Target[\"Date\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_missing_target_df = missing_Target[\"Date\"].value_counts().to_frame().reset_index()\nplot_missing_target_df.rename(columns = {'index':'Date', 'Date':'Count'}, inplace = True)\nplot_missing_target_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=plot_missing_target_df[\"Date\"], \n                         y=plot_missing_target_df[\"Count\"], \n                         mode='lines'))\n\nfig.update_layout(\n    title=f\"Stocks without Target Count per Date\",\n    xaxis_title=\"Date\",\n    yaxis_title=\"Count\",\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stocks\n\nstock_list.csv","metadata":{}},{"cell_type":"markdown","source":"\nSecuritiesCode: Local securities code.\n    EffectiveDate: The effective date. (Need clarification.)\n    Name: Name of security.\n    Section/Products: Section/Product.\n\n    NewMarketSegment: New market segment effective from 2022-04-04 (as of 15:30 JST on Mar 11 2022). For more information, please see Overview of Market Restructuring.\n    33SectorCode: 33 sector code.\n    33SectorName: 33 sector name.\n    17SectorCode: 17 sector code.\n    17SectorName: 17 sector name.\n　\n For more information about sector code and name, please see TOPIX Sector Indices / TOPIX-17 Series\n\n    NewIndexSeriesSizeCode: TOPIX New Index Series code.\n    NewIndexSeriesSize: TOPIX New Index Series name.\nFor more information about TOPIX New Index Series code and name, please see TOPIX New Index Series / Size-based TOPIX.\n\n    TradeDate: Trade date to calculate MarketCapitalization.\n    Close: Close price to calculate MarketCapitalization.\n    IssuedShares: Issued shares.\n    MarketCapitalization: Market capitalization on December 3, 2021.\n    Universe0: A flag of prediction target universe (top 2000 stocks by market capitalization).","metadata":{}},{"cell_type":"code","source":"display(stocks_info)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(stocks_df.head(5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stocks_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(pd.isna(stocks_df).sum()/len(stocks_df)*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stocks_missing_Date = stocks_df[stocks_df[\"TradeDate\"].isna()]\nstocks_missing_Date.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stocks_missing_segment = stocks_df[stocks_df[\"NewMarketSegment\"].isna()]\nstocks_missing_segment.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stocks_df[\"Universe0\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stocks_df[\"33SectorName\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sector = stocks_df[\"33SectorName\"].value_counts().to_frame()\nsector.reset_index(inplace=True)\nsector[\"percentage\"] = sector[\"33SectorName\"]/sector[\"33SectorName\"].sum()*100\nsector.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams[\"figure.figsize\"] = (30,10)\nplt.pie(sector[\"percentage\"], labels = sector[\"index\"])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stocks_df[\"Section/Products\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"section = stocks_df[\"Section/Products\"].value_counts().to_frame()\nsection.reset_index(inplace=True)\nsection[\"percentage\"] = section[\"Section/Products\"]/section[\"Section/Products\"].sum()*100\nsection","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"section[\"percentage\"] = section[\"Section/Products\"]/section[\"Section/Products\"].sum()*100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams[\"figure.figsize\"] = (30,10)\nplt.pie(section[\"percentage\"], labels = section[\"index\"])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Selecting the top 2000 Stocks (Universe0 Flag = True)","metadata":{}},{"cell_type":"code","source":"stocks2000_df = stocks_df[stocks_df[\"Universe0\"]]\ndisplay(stocks2000_df.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stocks2000_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stocks2000_df[\"33SectorName\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sector2000 = stocks2000_df[\"33SectorName\"].value_counts().to_frame()\nsector2000.reset_index(inplace=True)\nsector2000[\"percentage\"] = sector2000[\"33SectorName\"]/sector2000[\"33SectorName\"].sum()*100\nsector2000.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams[\"figure.figsize\"] = (40,10)\nplt.pie(sector2000[\"percentage\"], labels = sector2000[\"index\"])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"section2000 = stocks2000_df[\"Section/Products\"].value_counts().to_frame()\nsection2000.reset_index(inplace=True)\nsection2000[\"percentage\"] = section2000[\"Section/Products\"]/section2000[\"Section/Products\"].sum()*100\nsection2000","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams[\"figure.figsize\"] = (30,10)\nplt.pie(section2000[\"percentage\"], labels = section2000[\"index\"])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Merging Stock metadate with stock price","metadata":{}},{"cell_type":"code","source":"df_prices =  merge_metadata(stock_prices_df, stocks2000_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Free memory**","metadata":{}},{"cell_type":"markdown","source":"del stock_prices_df\ndel stocks2000_df\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-11T09:40:41.695924Z","iopub.execute_input":"2022-06-11T09:40:41.696238Z","iopub.status.idle":"2022-06-11T09:40:41.853016Z","shell.execute_reply.started":"2022-06-11T09:40:41.696207Z","shell.execute_reply":"2022-06-11T09:40:41.852083Z"}}},{"cell_type":"markdown","source":"**Calculating Target variable statistics**","metadata":{}},{"cell_type":"code","source":"mean_securities_df = df_prices.groupby([\"SecuritiesCode\"])[\"Target\"].mean()\ntotal_mean_securities = mean_securities_df.mean()\ntotal_mean_securities","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,5))\nsns.histplot(data=mean_securities_df.values, bins=100,\n             ax=ax)\nax.axvline(x=total_mean_securities, color='red', linestyle='dotted', linewidth=2, \n           label='Mean')\nax.set_title(\"Target Mean Distibution Securities\\n\"\n             f\"Min {round(mean_securities_df.min(), 4)} | \"\n             f\"Max {round(mean_securities_df.max(), 4)} | \"\n             f\"Skewness {round(mean_securities_df.skew(), 2)} | \"\n             f\"Kurtosis {round(mean_securities_df.kurtosis(), 2)}\")\nax.set_xlabel(\"Target Mean\")\nax.set_ylabel(\"Date Count\")\nax.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_date_df = df_prices.groupby([\"Date\"])[\"Target\"].mean()\ntotal_mean_date = mean_date_df.mean()\ntotal_mean_date","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,5))\nsns.histplot(data=mean_date_df.values, bins=100,\n             ax=ax)\nax.axvline(x=total_mean_date, color='red', linestyle='dotted', linewidth=2, \n           label='Mean')\nax.set_title(\"Target Mean Distibution Date\\n\"\n             f\"Min {round(mean_date_df.min(), 4)} | \"\n             f\"Max {round(mean_date_df.max(), 4)} | \"\n             f\"Skewness {round(mean_date_df.skew(), 2)} | \"\n             f\"Kurtosis {round(mean_date_df.kurtosis(), 2)}\")\nax.set_xlabel(\"Target Mean\")\nax.set_ylabel(\"Date Count\")\nax.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Add correlation maps: between different securities, sectors","metadata":{}},{"cell_type":"code","source":"### ADD CORRELATION MAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Target vs Sector33","metadata":{}},{"cell_type":"code","source":"target_sector = df_prices.groupby([\"33SectorName\"])[\"Target\"].mean()\ntarget_sector.sort_values(inplace=True, ascending=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_sector = target_sector.to_frame()\ntarget_sector.reset_index(inplace= True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (12,6))    \nfig = sns.barplot(x = \"33SectorName\", y = \"Target\", data = target_sector, ax=ax)\nax.set_title(\"Target Mean of Sectors\")\nax.tick_params(axis='x', rotation=90)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Target vs Section","metadata":{}},{"cell_type":"code","source":"target_section = df_prices.groupby([\"Section/Products\"])[\"Target\"].mean()\ntarget_section.sort_values(inplace=True, ascending=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_section = target_section.to_frame()\ntarget_section.reset_index(inplace= True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (12,6))    \nfig = sns.barplot(x = \"Section/Products\", y = \"Target\", data = target_section, ax=ax)\nax.set_title(\"Target Mean of Sections\")\nax.tick_params(axis='x', rotation=90)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Secondary stock prices","metadata":{}},{"cell_type":"markdown","source":"Securities with low liquidity (few opportunities to trade)","metadata":{}},{"cell_type":"code","source":"stock_prices_info","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(secondary_stock_prices_df.head(5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"secondary_stock_prices_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(pd.isna(secondary_stock_prices_df).sum()/len(secondary_stock_prices_df)*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Missing values**","metadata":{}},{"cell_type":"code","source":"missing_secondary_high = secondary_stock_prices_df[secondary_stock_prices_df[\"High\"].isna()]\ndisplay(missing_secondary_high.head(5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_secondary_high[\"Date\"].nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_missing_secondary_high_df = missing_secondary_high[\"Date\"].value_counts().to_frame().reset_index()\nplot_missing_secondary_high_df.rename(columns = {'index':'Date', 'Date':'Count'}, inplace = True)\nplot_missing_secondary_high_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As happened with the primary stock list 2020-10-01 is the day with the most amount of missing data\n","metadata":{}},{"cell_type":"markdown","source":"## Trades","metadata":{}},{"cell_type":"markdown","source":"Aggregated summary of trading volumes from the previous business week. Following is column information recorded in trades_spec.csv:\n\n    Date: Data published date, usually Thursday on the following week.\n    StartDate: The first trading date in this trading week.\n    EndDate: The last trading date in this trading week.\n    Section: Market division name.","metadata":{}},{"cell_type":"code","source":"trades_info","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(trades_df.head(5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Financials ","metadata":{}},{"cell_type":"code","source":"financials_info","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"financials_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"financials_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(pd.isna(financials_df).sum()/len(financials_df)*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Super interesting for the stock price prediction but most of the data is missing...","metadata":{}},{"cell_type":"markdown","source":"### Options","metadata":{}},{"cell_type":"markdown","source":"**File Description**\n\nData on the status of a variety of options based on the broader market. Many options include implicit predictions of the future price of the stock market and so may be of interest even though the options are not scored directly. Following is column information recorded in options_spec.csv:\n\n    DateCode: Unique ID for option price records, the combintion of Date and OptionCode.\n    Date: Trade date and time.\n    OptionsCode: Local securities code. Detailed information is provided in Identification Code Specifications for Futures and Options Transactionssakimono20220208-e.pdf).\n    WholeDayOpen: Opening price for whole trading day.\n    WholeDayHigh: Highest price for whole trading day.\n    WholeDayLow: Lowest price for whole trading day.\n    WholeDayClose: Closing price for whole trading day.\n    NightSessionOpen: Opening price for night session.\n    NightSessionHigh: Highest price for night session.\n    NightSessionLow: Lowest price for night session.\n    NightSessionClose: Closing price for night session.\n    DaySessionOpen: Opening price for day session.\n    DaySessionHigh: Highest price for day session.\n    DaySessionLow: Lowest price for day session.\n    DaySessionClose: Closing price for day session.\n    TradingVolume: Trading volume of the product/contract for the whole trading day.\n    OpenInterest: Open interest of the product/contract for the whole trading day\n    TradingValue: Trading value of the product/contract for the whole trading day\n    ContractMonth: Cotract year-month of the product/contract.\n    StrikePrice: Exercise price of product/contract.\n    DaySessionVolume: Trading volume of the product/contract for day session.\n    Putcall: 1 for put and 2 for call.\n    LastTradingDay: Last trading day.\n    SpecialQuotationDay: The day when the Special Quotation is calculated.\n    SettlementPrice: Settlement price.\n    TheoreticalPrice: The theoretical price at the end of a day session.\n    BaseVolatility: The volatility at the time of calculating the settlement price.\n    ImpliedVolatility: Implied volatility.\n    InterestRate: Interest rate for calculation.\n    DividendRate: Dividend yeild.\n    Dividend: Devidend.","metadata":{}},{"cell_type":"code","source":"options_info","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"options_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"options_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Cleaning data\n- Input missing days\n- Adjust price (Split- Reverse/split)\n- Standarize values?\n","metadata":{}},{"cell_type":"markdown","source":"#### Generate Adjusted Close price\nAdjustedClose using AdjustmentFactor value. This should reduce historical price gap caused by split/reverse-split.","metadata":{}},{"cell_type":"code","source":"df_prices_adj = adjust_price(df_prices)\ndf_prices_adj.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_prices_adj[\"CumulativeAdjustmentFactor\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_prices_adj.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Less missing values**","metadata":{}},{"cell_type":"code","source":"display(pd.isna(df_prices_adj).sum()/len(df_prices_adj)*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now the OHTC chart shows continuity**","metadata":{}},{"cell_type":"code","source":"plot_candle_with_target(df_prices, 9726, prime=True) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_candle_with_target_adjusted(adjust_price(df_prices), 9726, prime=True) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_candle_with_target(df_prices, 4582, prime=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_candle_with_target_adjusted(adjust_price(df_prices), 4582, prime=True) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_candle_with_target(df_prices, 1805, prime=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_candle_with_target_adjusted(adjust_price(df_prices), 1805, prime=True) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Feature Engineering\n- Create basic statics\n    1. Moving average\n    2. Exponential moving average\n    3. volatility\n- Do not create Features since you are going to be using RNN\n- Merge sentiment analysis data from Options\n    1. https://www.boerse-stuttgart.de/de-de/tools/euwax-sentiment/\n    2. https://www-mmds.sigmath.es.osaka-u.ac.jp/en/activity/vxj.php#:~:text=The%20Volatility%20Index%20Japan%20(VXJ,based%20on%20Nikkei225%20index%20options.\n- Check correlation secondary stock market target vs Primary stock market target\n","metadata":{"execution":{"iopub.status.busy":"2022-06-05T11:13:25.824025Z","iopub.execute_input":"2022-06-05T11:13:25.826736Z","iopub.status.idle":"2022-06-05T11:13:25.858499Z","shell.execute_reply.started":"2022-06-05T11:13:25.826586Z","shell.execute_reply":"2022-06-05T11:13:25.857394Z"}}},{"cell_type":"markdown","source":"**Correlogram to see if there is any autocorrelation**","metadata":{"execution":{"iopub.status.busy":"2022-06-05T11:13:47.03851Z","iopub.execute_input":"2022-06-05T11:13:47.038869Z","iopub.status.idle":"2022-06-05T11:13:47.045699Z","shell.execute_reply.started":"2022-06-05T11:13:47.038832Z","shell.execute_reply":"2022-06-05T11:13:47.04451Z"}}},{"cell_type":"code","source":"df_9726 =df_prices_adj[df_prices_adj[\"SecuritiesCode\"]==9726]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.figsize'] = [10, 5]\npd.plotting.autocorrelation_plot(df_9726[\"AdjustedClose\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.plotting.autocorrelation_plot(df_9726[\"Target\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It certainly look like we are dealing with a random walk, as there are no indications of any autocorrelation for any lag.\n\nBasically our LSTM found nothing of any real value to model and thus took the average value, along with a slight slope; we would have been just as well off with an extremely simplistic model of the form\n\nC\nl\no\ns\ne\nt\n∝\nC\nl\no\ns\ne\n(\nt\n−\n1\n)","metadata":{}},{"cell_type":"markdown","source":"Price is correlated but price change shows no correlation. Therefore, the target variable itself will not give us much info about future stock movements... We need a good Feature engineering","metadata":{}},{"cell_type":"markdown","source":"### Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"**From adjusted prices (individual)**\n- Price changes\n- Moving average\n- Exponential moving average\n- Volumen\n- Volatility\n- RSI: Low, Medium, High\n\n**From adjusted prices (GroupBy sector?)**","metadata":{}},{"cell_type":"markdown","source":"**Price changes**\n","metadata":{}},{"cell_type":"code","source":"period = [5,10,21,33]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in period:\n    df_9726[f\"pct{i}\"] = df_9726[\"AdjustedClose\"].pct_change(i)\ndisplay(df_9726.head(5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Simple Moving Average (SMA)**","metadata":{}},{"cell_type":"code","source":"period_avg = [10,20,50,60]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in period_avg:\n    df_9726[f\"SMA_{i}\"] = df_9726['AdjustedClose'].rolling(window=i).mean()\n\ndisplay(df_9726.tail(5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Exponential Moving Average (EMA)**","metadata":{}},{"cell_type":"code","source":"for i in period_avg:\n    df_9726[f\"EMA_{i}\"] = df_9726['AdjustedClose'].ewm(span=i,adjust=False).mean()\n\ndisplay(df_9726.tail(5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plotting the new features","metadata":{}},{"cell_type":"code","source":"col_avg = [\"AdjustedClose\",\"SMA_10\",\"SMA_20\",\"SMA_50\",\"SMA_60\",\"EMA_10\",\"EMA_20\",\"EMA_20\",\"EMA_60\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_9726Avg = df_9726[col_avg]\ndf_9726Avg.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams[\"figure.figsize\"] = (30,10)\ndf_9726Avg.plot(title = \"Avg analysis for Security Code\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col_SMA = [\"AdjustedClose\",\"SMA_10\",\"SMA_20\",\"SMA_50\",\"SMA_60\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_9726SMA = df_9726[col_SMA]\ndf_9726SMA.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_9726SMA.plot(title = \"Avg analysis for Security Code\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col_EMA = [\"AdjustedClose\",\"EMA_10\",\"EMA_20\",\"EMA_50\",\"EMA_60\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_9726EMA = df_9726[col_EMA]\ndf_9726EMA.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_9726EMA.plot(title = \"Avg analysis for Security Code\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_prices_feat = generate_feature(df_prices_adj)\ndf_prices_feat.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df_prices_adj\ndel df_9726\ndel df_9726EMA\ndel df_9726SMA\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Feature engineering by Group --> One Hot encoding**\n- SectorCode33\n- Section","metadata":{}},{"cell_type":"code","source":"def encoding(df):\n    cat_encoder = OneHotEncoder(handle_unknown='ignore')\n    train_set_cat_coded = cat_encoder.fit_transform(df[[\"33SectorName\",\"17SectorName\"]])\n    ls=[]\n    for i in cat_encoder.categories_:\n        for j in i:\n            ls.append(j)\n\n    train_set_cat_coded_ready = pd.DataFrame(train_set_cat_coded.todense(),columns = ls,index=df.index)\n    df = pd.concat([df, train_set_cat_coded_ready], axis=1)\n    \n    del train_set_cat_coded\n    del train_set_cat_coded_ready\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_encoder = OneHotEncoder(handle_unknown='ignore')\ntrain_set_cat_coded = cat_encoder.fit_transform(df_prices_feat[[\"33SectorName\",\"17SectorName\"]])\ntrain_set_cat_coded.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls=[]\nfor i in cat_encoder.categories_:\n    for j in i:\n        ls.append(j)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set_cat_coded_ready = pd.DataFrame(train_set_cat_coded.todense(),columns = ls,index=df_prices_feat.index)\ntrain_set_cat_coded_ready","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_prices_feat = pd.concat([df_prices_feat, train_set_cat_coded_ready], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_set_cat_coded\ndel train_set_cat_coded_ready\ndel options_df\ndel secondary_stock_prices_df\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Selecting features for the model**","metadata":{}},{"cell_type":"code","source":"col = [\"Date\",\"SecuritiesCode\",\"Target\",\"Volume\",\"AdjustedClose\",\"pct5\",\"pct10\",\"pct21\",\"pct33\",\"Volatility_5\",\"Volatility_10\",\"Volatility_21\",\"Volatility_33\",\"SMA_10\",\"SMA_20\",\"SMA_50\",\"SMA_60\",\"EMA_10\",\"EMA_20\",\"EMA_50\"] +ls\n#col","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Prediction Model","metadata":{}},{"cell_type":"code","source":"X = df_prices_feat[col]\nX=X.dropna().sort_values(['Date','SecuritiesCode'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y= X[\"Target\"].to_numpy()\nX=X.drop([\"Target\"],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Removing special characters in the column names**","metadata":{}},{"cell_type":"code","source":"X = X.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Time based Crossvalidation","metadata":{}},{"cell_type":"code","source":"params = {'n_estimators': 500,\n          'num_leaves' : 100,\n          'learning_rate': 0.1,\n          'colsample_bytree': 0.9,\n          'subsample': 0.8,\n          'reg_alpha': 0.4,\n          'metric': 'mae',\n          'random_state': 21}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ts_fold = TimeSeriesSplit(n_splits=12, gap=10000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_importance=pd.DataFrame()\nsharpe_ratio=[]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold, (train_idx, val_idx) in enumerate(ts_fold.split(X, y)):\n    \n    print(f\"\\n========================== Fold {fold+1} ==========================\")\n        \n    X_train, y_train = X.iloc[train_idx,:], y[train_idx]\n    X_valid, y_val = X.iloc[val_idx,:], y[val_idx]\n    \n    print(\"Train Date range: {} to {}\".format(X_train.Date.min(),X_train.Date.max()))\n    print(\"Valid Date range: {} to {}\".format(X_valid.Date.min(),X_valid.Date.max()))\n    \n    X_train.drop(['Date','SecuritiesCode'], axis=1, inplace=True)\n    X_val=X_valid[X_valid.columns[~X_valid.columns.isin(['Date','SecuritiesCode'])]]\n    val_dates=X_valid.Date.unique()[1:-1]\n    print(\"\\nTrain Shape: {} {}, Valid Shape: {} {}\".format(X_train.shape, y_train.shape, X_val.shape, y_val.shape))\n    \n    gbm = LGBMRegressor(**params).fit(X_train, y_train, \n                                      eval_set=[(X_train, y_train), (X_val, y_val)],\n                                      verbose=300, \n                                      eval_metric=['mae','mse'])\n    y_pred = gbm.predict(X_val)\n    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n    mae = mean_absolute_error(y_val, y_pred)\n    feat_importance[\"Importance_Fold\"+str(fold)]=gbm.feature_importances_\n    feat_importance.set_index(X_train.columns, inplace=True)\n        \n    rank=[]\n    X_val_df=X_valid[X_valid.Date.isin(val_dates)]\n    for i in X_val_df.Date.unique():\n        temp_df = X_val_df[X_val_df.Date == i].drop(['Date','SecuritiesCode'],axis=1)\n        temp_df[\"pred\"] = gbm.predict(temp_df)\n        temp_df[\"Rank\"] = (temp_df[\"pred\"].rank(method=\"first\", ascending=False)-1).astype(int)\n        rank.append(temp_df[\"Rank\"].values)\n\n    stock_rank=pd.Series([x for y in rank for x in y], name=\"Rank\")\n    df=pd.concat([X_val_df.reset_index(drop=True),stock_rank,\n                  df_prices_feat[df_prices_feat.Date.isin(val_dates)]['Target'].reset_index(drop=True)], axis=1)\n    sharpe=calc_spread_return_sharpe(df)\n    sharpe_ratio.append(sharpe)\n    print(\"Valid Sharpe: {}, RMSE: {}, MAE: {}\".format(sharpe,rmse,mae))\n    \n    del X_train, y_train,  X_val, y_val\n    gc.collect()\n    \nprint(\"\\nAverage cross-validation Sharpe Ratio: {:.4f}, standard deviation = {:.2f}.\".format(np.mean(sharpe_ratio),np.std(sharpe_ratio)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"feat_importance['avg'] = feat_importance.mean(axis=1)\nfeat_importance = feat_importance.sort_values(by='avg',ascending=True)\npal=sns.color_palette(\"plasma_r\", 29).as_hex()[2:]\n\nfig=go.Figure()\nfor i in range(len(feat_importance.index)):\n    fig.add_shape(dict(type=\"line\", y0=i, y1=i, x0=0, x1=feat_importance['avg'][i], \n                       line_color=pal[::-1][i],opacity=0.7,line_width=4))\n    fig.add_trace(go.Scatter(x=feat_importance['avg'], y=feat_importance.index, mode='markers', \n                             marker_color=pal[::-1], marker_size=8,\n                             hovertemplate='%{y} Importance = %{x:.0f}<extra></extra>'))\n    fig.update_layout(title='Overall Feature Importance', \n                      xaxis=dict(title='Average Importance',zeroline=False),\n                      yaxis_showgrid=False, margin=dict(l=120,t=80),\n                      height=700, width=800)\n    fig.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T14:34:47.647904Z","iopub.execute_input":"2022-06-12T14:34:47.648173Z","iopub.status.idle":"2022-06-12T14:34:48.178403Z","shell.execute_reply.started":"2022-06-12T14:34:47.648144Z","shell.execute_reply":"2022-06-12T14:34:48.177297Z"}}},{"cell_type":"code","source":"del df_prices_feat\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.API Submission","metadata":{}},{"cell_type":"code","source":"import jpx_tokyo_market_prediction\nenv = jpx_tokyo_market_prediction.make_env()\niter_test = env.iter_test()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols=['Date','SecuritiesCode','Open','High','Low','Close','Volume','AdjustmentFactor']\nstock_prices_df=stock_prices_df[stock_prices_df.Date>='2021-08-01'][cols]\n\n#cols_fin = [\"Date\",\"Volume\",\"AdjustedClose\",\"pct5\",\"pct10\",\"pct21\",\"pct33\",\"Volatility_5\",\"Volatility_10\",\"Volatility_21\",\"Volatility_33\",\"SMA_10\",\"SMA_20\",\"SMA_50\",\"SMA_60\",\"EMA_10\",\"EMA_20\",\"EMA_50\"]\ncols_fin = col\ncols_fin.remove(\"Target\")\ncounter = 0\nfor (prices, options, financials, trades, secondary_prices, sample_prediction) in iter_test:\n    \n    ## Loading API data and combine it with the dataset\n    current_date = prices[\"Date\"].iloc[0]\n    if counter == 0:\n        df_price_raw = stock_prices_df.loc[stock_prices_df[\"Date\"] < current_date]\n    \n    df_price_raw = pd.concat([df_price_raw, prices[cols]]).reset_index(drop=True)\n    \n    ## Feature engineering\n    df_price = adjust_price(df_price_raw)\n    features = merge_metadata(df_price, stocks2000_df)  \n    features = generate_feature(features)\n    features = encoding(features) \n    features = features.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n    features = features[X.columns.to_list()]\n    feat = features[features.Date == current_date].drop(['SecuritiesCode','Date'],axis=1)\n    \n    ## Prediction using the Model\n    feat[\"pred\"] = gbm.predict(feat)\n    \n    ## Generate Ranking 0-1999\n    feat[\"Rank\"] = (feat[\"pred\"].rank(method=\"first\", ascending=False)-1).astype(int)\n    \n    ## Input the ranking to the submission file\n    sample_prediction[\"Rank\"] = feat[\"Rank\"].values\n    display(sample_prediction.head())\n    \n    ## Input the ranking to the submission file\n    assert sample_prediction[\"Rank\"].notna().all()\n    assert sample_prediction[\"Rank\"].min() == 0\n    assert sample_prediction[\"Rank\"].max() == len(sample_prediction[\"Rank\"]) - 1\n    \n    ## Submitt prediction file\n    env.predict(sample_prediction)\n    counter += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}